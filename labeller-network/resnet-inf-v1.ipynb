{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import gym\n",
    "import minerl\n",
    "import pickle\n",
    "\n",
    "# --------- HYPERPARAMETERS ---------\n",
    "keys_classes = 22\n",
    "camera_classes = 2\n",
    "learning_rate = 1e-4\n",
    "batch_size = 1\n",
    "num_epochs = 1000\n",
    "num_workers = 4\n",
    "channels, temporal_depth, height, width = 1, 7, 90, 160  # Video dimensions\n",
    "\n",
    "# Define the number of layers for each block in the ResNet3D\n",
    "resnet_layers = [2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([112, 160, 90])\n"
     ]
    }
   ],
   "source": [
    "video_path = '/mnt/d/py/vpt/data/labeller-training/video/mc-0.mp4'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "def read_video_to_memory(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.resize(gray_frame, (height, width))\n",
    "        frames.append(gray_frame)\n",
    "        \n",
    "\n",
    "    cap.release()\n",
    "    return torch.from_numpy(np.array(frames))\n",
    "\n",
    "# video_tensor will equal [] because I tried to load a game instance and reset the video content\n",
    "video_tensor = read_video_to_memory(video_path)\n",
    "print(video_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock3D(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # --------- RESNET3D DEFINITION ---------\n",
    "\n",
    "class ResNet3D(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNet3D, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv3d(channels, self.in_channels, kernel_size=7, stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Layers\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # --------- IDM MODEL DEFINITION ---------\n",
    "\n",
    "class KeysIDM(nn.Module):\n",
    "    def __init__(self, keys_classes):\n",
    "        super(KeysIDM, self).__init__()\n",
    "        self.keys_resnet3d = ResNet3D(BasicBlock3D, resnet_layers, keys_classes)\n",
    "        self.camera_resnet3d = ResNet3D(BasicBlock3D, resnet_layers, camera_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys_out = self.keys_resnet3d(x)\n",
    "        # camera_out = self.camera_resnet3d(x)\n",
    "        keys_out = self.sigmoid(keys_out)\n",
    "        return keys_out\n",
    "    \n",
    "class CameraIDM(nn.Module):\n",
    "    def __init__(self, camera_classes):\n",
    "        super(CameraIDM, self).__init__()\n",
    "        # self.keys_resnet3d = ResNet3D(BasicBlock3D, resnet_layers, keys_classes)\n",
    "        self.camera_resnet3d = ResNet3D(BasicBlock3D, resnet_layers, camera_classes)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # keys_out = self.keys_resnet3d(x)\n",
    "        camera_out = self.camera_resnet3d(x)\n",
    "        # keys_out = self.sigmoid(keys_out)\n",
    "        return camera_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(rand_indices):\n",
    "    \n",
    "    batch = torch.zeros((batch_size, 1, temporal_depth, width, height), dtype=video_tensor.dtype)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        batch[i, 0] = video_tensor[rand_indices[i]:rand_indices[i] + temporal_depth]\n",
    "\n",
    "    return batch\n",
    "\n",
    "def get_actions(action_dict):\n",
    "\n",
    "    # Define default actions\n",
    "    default_actions = {\n",
    "        \"attack\": 0, \"back\": 0, \"drop\": 0, \"forward\": 0, \n",
    "        \"hotbar.1\": 0, \"hotbar.2\": 0, \"hotbar.3\": 0, \"hotbar.4\": 0, \"hotbar.5\": 0,\n",
    "        \"hotbar.6\": 0, \"hotbar.7\": 0, \"hotbar.8\": 0, \"hotbar.9\": 0, \"inventory\": 0,\n",
    "        \"jump\": 0, \"left\": 0, \"right\": 0, \"pickItem\": 0, \"sneak\": 0, \"sprint\": 0,\n",
    "        \"swapHands\": 0, \"use\": 0, \"camera\": [0.0, 0.0]\n",
    "    }\n",
    "    # Update with the actual values from action_dict\n",
    "    default_actions.update(action_dict)\n",
    "    # Extract keyboard actions and camera actions\n",
    "    keyboard_actions = [1 if default_actions[key] else 0 for key in default_actions if key not in [\"camera\", \"ESC\", \"noop\"]]\n",
    "    camera_actions = default_actions.get(\"camera\", [0.0, 0.0])\n",
    "\n",
    "    return keyboard_actions, camera_actions\n",
    "\n",
    "\n",
    "with open('/mnt/d/py/vpt/data/labeller-training/actions/mc-0.json', 'r') as json_file:\n",
    "    actions_data = json.load(json_file)\n",
    "\n",
    "\n",
    "\n",
    "def get_batch():\n",
    "    \n",
    "    total_frames = video_tensor.shape[0]\n",
    "    # print(video_tensor.shape)\n",
    "    # print([random.randint(0, total_frames-temporal_depth) for _ in range(batch_size)])\n",
    "    # print(total_frames)\n",
    "    rand_indices = [random.randint(0, total_frames-temporal_depth) for _ in range(batch_size)]\n",
    "    batch_frames = get_video(rand_indices)\n",
    "\n",
    "\n",
    "    batch_keys = []\n",
    "    batch_cams = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        keyboard, camera = get_actions(actions_data[rand_indices[i]+(temporal_depth//2)])\n",
    "\n",
    "        batch_keys.append(keyboard)\n",
    "        batch_cams.append(camera)\n",
    "\n",
    "    return batch_frames.to(device).float() / 255.0, torch.tensor(batch_keys, dtype=torch.float32, device='cuda'), torch.tensor(batch_cams, dtype=torch.float32, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/resnet-keyspred.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m keys_idm_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m camera_idm_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/resnet-keyspred.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     keys_idm_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/resnet-camerapred.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/mnt/d/py/vpt/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/resnet-keyspred.pkl'"
     ]
    }
   ],
   "source": [
    "# Assuming you have the train_loader set up correctly with your dataset\n",
    "\n",
    "keys_idm_model = KeysIDM(keys_classes=keys_classes).to(device)\n",
    "camera_idm_model = CameraIDM(camera_classes=camera_classes).to(device)\n",
    "keys_idm_model.eval()\n",
    "camera_idm_model.eval()\n",
    "\n",
    "\n",
    "# with open('models/resnet-keyspred.pkl', 'rb') as f:\n",
    "#     keys_idm_model = pickle.load(f)\n",
    "\n",
    "\n",
    "with open('models/resnet-camerapred.pkl', 'rb') as f:\n",
    "    camera_idm_model = pickle.load(f)\n",
    "\n",
    "keys_idm_model = keys_idm_model.to(device)\n",
    "camera_idm_model = camera_idm_model.to(device)\n",
    "# optimizer = optim.Adam(idm_model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# Initialize the Minecraft environment\n",
    "env = gym.make('MineRLBasaltBuildVillageHouse-v0')\n",
    "# env = gym.make('MineRLBasaltFindCave-v0')\n",
    "\n",
    "env.seed(2143)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "\n",
    "    # frames = []\n",
    "\n",
    "RESOLUTION = (640, 360)  # Resolution at which to capture and save the video\n",
    "screen = pygame.display.set_mode(RESOLUTION)\n",
    "pygame.display.set_caption('Minecraft')\n",
    "SENS = 0.05\n",
    "\n",
    "\n",
    "\n",
    "pygame.mouse.set_visible(True)\n",
    "pygame.mouse.set_pos(screen.get_width() // 2, screen.get_height() // 2)  # Center the mouse\n",
    "pygame.event.set_grab(False)\n",
    "\n",
    "keys_actions_arr = [\n",
    "    \"attack\", \"back\", \"drop\", \"forward\", \"hotbar.1\", \"hotbar.2\", \"hotbar.3\", \"hotbar.4\", \"hotbar.5\",\n",
    "    \"hotbar.6\", \"hotbar.7\", \"hotbar.8\", \"hotbar.9\", \"inventory\", \"jump\", \"left\", \"right\", \"pickItem\",\n",
    "    \"sneak\", \"sprint\", \"swapHands\", \"use\"\n",
    "]\n",
    "\n",
    "final_action = {}\n",
    "\n",
    "try:\n",
    "    # Iterate over data loader\n",
    "    for i in range(video_tensor.shape[0]-temporal_depth):\n",
    "    \n",
    "        # start_time = time.time()\n",
    "        # framestack = video_loader()\n",
    "        # end_time = time.time()\n",
    "      \n",
    "        \n",
    "        frames = video_tensor[i:i+temporal_depth].unsqueeze(0).to(device).float() / 255.0\n",
    "        frames = frames.unsqueeze(0)\n",
    "        # print(frames.shape)\n",
    "    \n",
    "        done = False\n",
    "        keys_out = keys_idm_model(frames)\n",
    "        camera_out = camera_idm_model(frames)\n",
    "        \n",
    "        keys_action_predicted = keys_out.squeeze().round().tolist()\n",
    "        camera_out = camera_out.squeeze().cpu().detach().numpy()\n",
    "        # print(f'dataloader returned: {keys_action_predicted}')\n",
    "        # print(keys_action_predicted)\n",
    "\n",
    "        \n",
    "    \n",
    "        keys_converted_act = [int(x) for x in keys_action_predicted]\n",
    "        keys_actions_dict = dict(zip(keys_actions_arr, keys_converted_act))\n",
    "        # print(keys_actions_dict)\n",
    "\n",
    "        image = np.array(obs['pov'])\n",
    "\n",
    "        image = np.flip(image, axis=1)\n",
    "        image = np.rot90(image)\n",
    "        # image = image * 0.1 # <- brightness\n",
    "        image = pygame.surfarray.make_surface(image)\n",
    "        screen.blit(image, (0, 0))\n",
    "        pygame.display.update()\n",
    "    \n",
    "        \n",
    "    \n",
    "        # Get the current state of all keys\n",
    "        terminate_keys = pygame.key.get_pressed()\n",
    "    \n",
    "        action = {'noop': []}\n",
    "\n",
    "    \n",
    "        # Now, use delta_x and delta_y for the camera movement\n",
    "        # camera_out[0] *= 255\n",
    "        # camera_out[1] *= 255\n",
    "        # print(camera_out)\n",
    "        action['camera'] = camera_out.tolist()\n",
    "        # print(camera_action)\n",
    "        # print(keys_actions)\n",
    "        \n",
    "    \n",
    "        # Add the in-game 'ESC' action to the beginning of the action\n",
    "        final_action = {'ESC': 0, **keys_actions_dict, **action}\n",
    "        # print(final_action)\n",
    "        # action_log.append(action)\n",
    "    \n",
    "        # Apply the action in the environment\n",
    "        obs, reward, done, _ = env.step(final_action)\n",
    "    \n",
    "        # Check if the 'q' key is pressed to terminate the loop\n",
    "        if terminate_keys[pygame.K_q]:\n",
    "            break\n",
    "    \n",
    "        # Handle pygame events to avoid the window becoming unresponsive\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:    \n",
    "\n",
    "        # env.render()\n",
    "    \n",
    "    \n",
    "    # Cleanup\n",
    "    # out.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "    pygame.quit()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
